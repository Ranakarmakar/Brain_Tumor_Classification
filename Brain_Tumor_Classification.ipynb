{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ddf1c58",
   "metadata": {},
   "source": [
    "# Brain Tumor Classification (MRI)\n",
    "#Dataset - https://www.kaggle.com/sartajbhuvaji/brain-tumor-classification-mri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69845af5",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87db5b8a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce803e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e5b1bb",
   "metadata": {},
   "source": [
    "## Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b046d890",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2633621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2870 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('dataset_large/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                             class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe176194",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c2385436",
   "metadata": {},
   "source": [
    "## Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09926647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset_large/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dc9b04",
   "metadata": {},
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42e72bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the CNN\n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8192db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09a90dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ce6cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second convolutional layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dc16c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 - Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b45889bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4 - Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d926ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 - Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be337dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 - Training the CNN\n",
    "\n",
    "# Compiling the CNN\n",
    "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b2ec06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "90/90 [==============================] - 15s 166ms/step - loss: 0.1057 - accuracy: 0.9571 - val_loss: 0.5887 - val_accuracy: 0.7182\n",
      "Epoch 2/20\n",
      "90/90 [==============================] - 15s 163ms/step - loss: 0.1024 - accuracy: 0.9571 - val_loss: 0.8683 - val_accuracy: 0.5955\n",
      "Epoch 3/20\n",
      "90/90 [==============================] - 14s 160ms/step - loss: 0.1130 - accuracy: 0.9530 - val_loss: 0.6776 - val_accuracy: 0.6955\n",
      "Epoch 4/20\n",
      "90/90 [==============================] - 14s 159ms/step - loss: 0.0953 - accuracy: 0.9638 - val_loss: 0.4951 - val_accuracy: 0.7727\n",
      "Epoch 5/20\n",
      "90/90 [==============================] - 15s 165ms/step - loss: 0.0839 - accuracy: 0.9669 - val_loss: 0.6527 - val_accuracy: 0.6909\n",
      "Epoch 6/20\n",
      "90/90 [==============================] - 14s 160ms/step - loss: 0.0791 - accuracy: 0.9679 - val_loss: 0.5577 - val_accuracy: 0.7455\n",
      "Epoch 7/20\n",
      "90/90 [==============================] - 14s 159ms/step - loss: 0.0826 - accuracy: 0.9679 - val_loss: 0.8011 - val_accuracy: 0.6591\n",
      "Epoch 8/20\n",
      "90/90 [==============================] - 15s 162ms/step - loss: 0.0680 - accuracy: 0.9721 - val_loss: 0.7587 - val_accuracy: 0.7000\n",
      "Epoch 9/20\n",
      "90/90 [==============================] - 14s 158ms/step - loss: 0.0648 - accuracy: 0.9732 - val_loss: 0.8433 - val_accuracy: 0.6773\n",
      "Epoch 10/20\n",
      "90/90 [==============================] - 14s 158ms/step - loss: 0.0617 - accuracy: 0.9791 - val_loss: 0.7638 - val_accuracy: 0.7091\n",
      "Epoch 11/20\n",
      "90/90 [==============================] - 14s 156ms/step - loss: 0.0624 - accuracy: 0.9756 - val_loss: 0.8181 - val_accuracy: 0.6909\n",
      "Epoch 12/20\n",
      "90/90 [==============================] - 14s 155ms/step - loss: 0.0437 - accuracy: 0.9857 - val_loss: 0.8414 - val_accuracy: 0.7591\n",
      "Epoch 13/20\n",
      "90/90 [==============================] - 14s 153ms/step - loss: 0.0515 - accuracy: 0.9836 - val_loss: 0.8294 - val_accuracy: 0.7227\n",
      "Epoch 14/20\n",
      "90/90 [==============================] - 14s 153ms/step - loss: 0.0692 - accuracy: 0.9742 - val_loss: 0.7748 - val_accuracy: 0.7409\n",
      "Epoch 15/20\n",
      "90/90 [==============================] - 14s 159ms/step - loss: 0.0484 - accuracy: 0.9843 - val_loss: 0.8955 - val_accuracy: 0.7182\n",
      "Epoch 16/20\n",
      "90/90 [==============================] - 14s 155ms/step - loss: 0.0398 - accuracy: 0.9885 - val_loss: 0.9067 - val_accuracy: 0.7136\n",
      "Epoch 17/20\n",
      "90/90 [==============================] - 14s 158ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 0.6477 - val_accuracy: 0.8182\n",
      "Epoch 18/20\n",
      "90/90 [==============================] - 14s 155ms/step - loss: 0.0405 - accuracy: 0.9829 - val_loss: 0.6376 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "90/90 [==============================] - 14s 153ms/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.8547 - val_accuracy: 0.7545\n",
      "Epoch 20/20\n",
      "90/90 [==============================] - 14s 155ms/step - loss: 0.0244 - accuracy: 0.9913 - val_loss: 1.0178 - val_accuracy: 0.7545\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29205b8f790>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the CNN on the Training set and evaluating it on the Test set\n",
    "cnn.fit(x = training_set, validation_data = test_set, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f190f10",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "018905a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,625,281\n",
      "Trainable params: 1,625,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3329f533",
   "metadata": {},
   "source": [
    "## Saving The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21daaf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save(\"tumor_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69dbe35",
   "metadata": {},
   "source": [
    "## Loaded Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb02676c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12544)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1605760   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,625,281\n",
      "Trainable params: 1,625,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"tumor_model.h5\")\n",
    "x = loaded_model.summary()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7cd96c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a97a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a28669db",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce94b6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/yes_or_no.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = cnn.predict(test_image)\n",
    "training_set.class_indices\n",
    "print(result)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e016b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'yes'\n",
    "else:\n",
    "    prediction = 'no'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f41ec817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "cnn1 = load_model('tumor_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6b84591",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img('dataset/single_prediction/yes_or_no2.jpg', target_size = (64, 64))\n",
    "test_imag = image.img_to_array(img)\n",
    "test_img = np.expand_dims(test_imag, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3181a0c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5efcefd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn1.predict(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4e52bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image1 = image.load_img('dataset/single_prediction/yes_or_no3.jpg', target_size = (64, 64))\n",
    "test_image2 = image.img_to_array(test_image1)\n",
    "test_image3 = np.expand_dims(test_image2, axis = 0)\n",
    "test_image3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb19b941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x29206F560A0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63e967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
